\documentclass[fleqn]{llncs}
\usepackage{latexsym}
\usepackage{amssymb,amsmath}
\usepackage{stmaryrd}
\usepackage{graphicx}
%\usepackage{color}
\usepackage{hyperref}
\usepackage{phonetic}
\usepackage{xargs}
\usepackage[pdftex,dvipsnames]{xcolor}
\usepackage{listings}

\lstset{language=ml,basicstyle=\ttfamily\small,breaklines=true,showspaces=false,
  showstringspaces=false,breakatwhitespace=true,texcl=true,
  escapeinside={(*}{*)}}

\input{bt-proj-desc-def}

\usepackage[colorinlistoftodos,textsize=tiny]{todonotes}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}

\title{Biform Theories: Project Description\thanks{This research was supported by NSERC.}}

\author{Jacques Carette, William M. Farmer, and Yasmine Sharoda}

\institute{%
Computing and Software, McMaster University, Canada\\
\url{http://www.cas.mcmaster.ca/~carette}\\
\url{http://imps.mcmaster.ca/wmfarmer}\\[1.5ex]
\today
}

\pagestyle{headings}

\begin{document}

\maketitle

\begin{abstract}
A \emph{biform theory} is a combination of an axiomatic theory and an
algorithmic theory that supports the integration of reasoning and
computation.  These are ideal for specifying and reasoning about
algorithms that manipulate mathematical expressions.  However,
formalizing biform theories is challenging since it requires the means
to express statements about the interplay of what these algorithms do
and what their actions mean mathematically.  This paper describes a
project to develop a methodology for expressing and managing
mathematical knowledge as a network of biform theories.  It is a
subproject of MathScheme, a long-term project at McMaster University
to produce a framework for integrating formal deduction and symbolic
computation.
\end{abstract}

\iffalse 

\textbf{Keywords:} Axiomatic mathematics, algorithmic mathematics, biform
theories, symbolic computation, reasoning about syntax, meaning
formulas, theory graphs.

\fi

\noindent
This paper presents a project named \emph{Biform Theories} that is a
subproject of MathScheme~\cite{CaretteEtAl11}, a long-term project at
McMaster University to produce a framework for integrating formal
deduction and symbolic computation.  The motivation, background
ideas, objectives, work plan status, and related work for the
project are described in the sections below.

\section{Motivation}\label{sec:problem}

\todo{Jacques should complete this section with help from Yasmine with
  examples.}

Computer algebra and theorem proving systems manipulate syntactic representation of mathematical knowledge. However, their way of manipulating them is very different from each other. To illustrate the difference, let's consider the example of factoring polynomials, Given a polynomial $p$ in extended canonical form, $\Sigma_{i=0}^{n}a_i x^i$, factorize it into the product of irreducible polynomials (polynomials that cannot be further factorized) \cite{von2003modern}.
 
A theorem proving system (TPS) will use an axiomatic theory to describe this problem. It defines constants representing the language of polynomials and axioms describing their properties. 
Since polynomials are rings, the axiomatic theory would be similar to the theory of rings with additional axioms representing the different forms that a polynomial can take. The additional axioms include: 
\begin{itemize}
	\item An axiom describing a polynomial in extended canonical form 
	\item An axiom describing what an irreducible polynomial is 
	\item An axioms describing the result of the factorization. 
\end{itemize}
The axiomatic theory gives the tools to describe how a what factoring of a polynomial is, but is not capable of describing procedures to compute it. 
\todo{Is this accurate?}
. 
On the other hand, a computer algebra system (CAS) would use an algebraic theory to represent factorization of polynomials. It describes procedures to calculate the factorization and produce results.  Yet, there is no guarantee the results produced are correct. The algorithmic approach is not concerned with specifying the procedures described. 
Neither representations is capable of producing results that are formally specified. 

We used factoring polynomials as an example, but all syntax-based mathematical algorithms (SBMAs) suffer from the same problem. SBMAs are algorithms that produces results by manipulating the syntax of the input. Examples of SBMAs include factoring polynomials, manipulating matrices, computing derivatives and others. They are frequently used in mathematics, that it makes sense to consider reasoning about the behavior of their implementations are crucial task. 
To be able to perform this reasoning, we need a way to connect a piece of code to its value. In other words, we need to be able to connect syntax and semantics. Biform theories make this possible. 

A biform theory is defined as a tuple $(L,\Pi, \Gamma)$ where 
\begin{itemize}
	\item $L$ defines constants describing the language of polynomials
	\item $\Pi$ defines the algorithms (transformers) that manipulate the syntax of the polynomial to perform different operations - as in the algorithmic theory. 
	\item $\Gamma$ is a set of axioms. We differentiate between two types of axioms. Some axioms describe the behavior of the constants of the language - as in axiomatic theory. Other axioms, called the meaning formula, which describes the behavior of the transformer by describing how the mathematical meaning of the output expression relates to that of the input expression. 
\end{itemize}
Biform theories enable the specification of algorithms (transformers) via meaning formulas using quotation and evaluation. Consider the example of factoring polynomials. A meaning formula for factorization would subsume the formula 
\begin{equation*}
\sembrack{ \synbrack{x^2 - 1} } \equiv \sembrack {\synbrack{(x - 1)(x + 1)}}
\end{equation*}
which cannot be expressed without a mean to talk about the semantics of the syntactic representation of the mathematical value. 
 
After presenting a piece of mathematical knowledge, there is a need to connect it to other existing pieces. We believe the best way to do that is by presenting mathematical knowledge as a biform theory graph. For example, we know that polynomials are rings. Therefore, the biform theory of polynomials should be an extension of the biform theory of rings. Adding a new operation to manipulate polynomials boils down to extending the theory of polynomials with the new operation. This way, modularity is forced as well as leveraging the information presented by adding the theory morphisms that enable transportation of results among the graph nodes (the biform theories).  
\todo{More about theory graph, eg: talk about the little theories approach.}

\section{Background Ideas}

A \emph{transformer} is an algorithm that implements a function $\sE^n
\tarrow \sE$ where $\sE$ is a set of expressions.  Transformers can
manipulate expressions in various ways.  Simple transformers, for
example, build bigger expressions from pieces, select components of
expressions, or check whether a given expression satisfies some
syntactic property.  More sophisticated transformers manipulate
expressions in mathematically meaningful ways.  We call these kinds of
transformers \emph{syntax-based mathematical algorithms
  (SBMAs)}~\cite{Farmer13}.  Examples include algorithms that apply
arithmetic operations to numerals, factor polynomials, transpose
matrices, and symbolically differentiate expressions with variables.
The \emph{computational behavior} of a transformer is the relationship
between its input and output expressions.  When the transformer is an
SBMA, its \emph{mathematical meaning} is the relationship between the
mathematical meanings of its input and output expressions.

A \emph{biform theory} $T$ is a triple $(L,\Pi,\Gamma)$ where $L$ is a
language of some underlying logic, $\Pi$ is a set of transformers that
implement functions on expressions of $L$, and $\Gamma$ is a set of
formulas of
$L$~\cite{CaretteFarmer08,Farmer07b,FarmerMohrenschildt03}.  $L$
includes, for each transformer $\pi \in \Pi$, a name for the function
implemented by $\pi$.  The members of $\Gamma$ are the \emph{axioms}
of $T$.  They specify the meaning of the nonlogical symbols in $L$
including the names of the transformers of $T$.  In particular,
$\Gamma$ may contain specifications of the computational behavior of
the transformers in $\Pi$ and of the mathematical meaning of the SBMAs
in $\Pi$.  We say $T$ is an \emph{axiomatic theory} if $\Pi$ is empty
and an \emph{algorithmic theory} if $\Gamma$ is empty.

Formalizing a biform theory in the underlying logic requires an
infrastructure for reasoning about the expressions manipulated by the
transformers as syntactic entities.  The infrastructure provides a
basis for \emph{metareasoning with reflection}~\cite{FarmerArxiv16}.
There are two main approaches for obtaining this
infrastructure~\cite{Farmer13}.  The \emph{local approach} is to
produce a deep embedding of a sublanguage $L'$ of $L$ that include all
the expressions manipulated by the transformers of $\Pi$.  The
\emph{global approach} is to replace the underlying logic of $L$ with
a logic such as~\cite{FarmerArxiv16} that has an inductive
type of \emph{syntactic values} that represent the expressions in $L$
and global quotation and evaluation operators.

A complex body of mathematical knowledge can be represented in
accordance with the \emph{little theories method}~\cite{FarmerEtAl92b}
as a \emph{theory graph}~\cite{Kohlhase14} consisting of axiomatic
theories as nodes and theory morphisms as directed edges.  A
\emph{theory morphism} is a meaning-preserving mapping from the
formulas of one axiomatic theory to the formulas of another.  The
theories --- may have different underlying logics --- serve as
abstract mathematical models and the morphisms serve as information
conduits that enable theory components such as definitions and
theorems to be transported from one theory to
another~\cite{BarwiseSeligman97}.  A theory graph enables mathematical
knowledge to be formalized in the most convenient underlying logic at
the most convenient level of abstraction using the most convenient
vocabulary.  The connections made by the theory morphisms in a theory
graph then provide the means to find this knowledge and apply it in
other contexts.

A \emph{biform theory graph} is a theory graph whose nodes are biform
theories. Having the same benefits as theory graphs of axiomatic
theories, biform theory graphs are well suited for representing
mathematical knowledge that is expressed both axiomatically and
algorithmically.
  
\section{Project Objectives}

The general objective of the Biform Theories project is:

\bi

  \item[] \textbf{GenObj.} Develop a methodology for expressing and
    managing mathematical knowledge as a biform theory graph.

\ei

\noindent
Our strategy for achieving this general objective is to pursue the
following specific objectives:

\bi

  \item[]\textbf{SpecOBj 1.} Design a logic \mname{Log} that is
    version of simple type theory~\cite{Farmer08} with an inductive
    type of syntactic values, a global quotation operator, and a
    global evaluation operator.  In addition to a syntax and
    semantics, define a proof system for \mname{Log} and a notion of a
    theory morphism from one axiomatic theory of \mname{Log} to
    another.  Demonstrate that SBMAs can be defined in \mname{Log} and
    that their mathematical meanings can be stated and proved in using
    \mname{Log}'s proof system.

\medskip

  \item[]\textbf{SpecOBj 2.} Produce an implementation \mname{Impl} of
    \mname{Log}.  Demonstrate that SBMAs can be defined in
    \mname{Impl} and that their mathematical meanings can be stated
    and proved in \mname{Impl}.

\medskip

  \item[]\textbf{SpecOBj 3.} Enable biform theories to be defined in
    \mname{Impl}.  Introduce a mechanism for applying transformers
    defined outside of \mname{Impl} to expressions of \mname{Log}.

\medskip

  \item[]\textbf{SpecOBj 4.} Enable theory graphs of biform theories
    to be defined in \mname{Impl}.  Introduce mechanisms for
    transporting definitions, theorems, and transformers from a biform
    theory $T$ to an instance $T'$ of $T$ via a theory morphism from
    $T$ to $T'$.

\medskip

  \item[]\textbf{SpecOBj 5.} Design and implement in \mname{Impl} a
    scheme for defining generic transformers in a theory graph $T$
    that can be specialized, when transported to an instance $T'$ of
    $T$, using the properties exhibited in $T'$.

\ei


\section{Work Plan Status}

The work plan for the project is to achieve the five specific
objectives described above more or less in the order of their
presentation.  This section describes the parts of the work plan that
have been completed as well as the parts that remain to be done.

\subsection*{SpecObj 1: Logic with Quotation and Evaluation}

This objective has been largely been achieved.  We have developed
{\churchqe}~\cite{Farmer18}, a version of Church's type
theory~\cite{Church40} with global quotation and evaluation operators.
(Church's type theory is a popular form of simple type theory with
lambda notation.)  The syntax of {\churchqe} has the machinery of
{\qzero}~\cite{Andrews02}, Andrews' version of Church's type theory
plus an inductive type $\epsilon$ of syntactic values, a partial
quotation operator, and a typed evaluation operator.  The semantics of
{\churchqe} is based on Henkin-style general models~\cite{Henkin50}.
The proof system for {\churchqe} is an extension of the proof system
for {\qzero}.

We show in~\cite{Farmer18} that {\churchqe} is suitable for defining
SBMAs and stating and proving their mathematical meanings.  In
particular, we prove within the proof system for {\churchqe} the
mathematical meaning of an symbolic differentiation algorithm for
polynomials.

We have also defined {\churchuqe}~\cite{Farmer17}, a variant of
{\churchqe} in which undefinedness is incorporated in {\churchqe}
according to the traditional approach to
undefinedness~\cite{Farmer04}.  Better suited than {\churchqe} as a
logic for interconnecting axiomatic theories, we have defined in
{\churchuqe} a notion of a theory morphism~\cite{Farmer17}.

\subsection*{SpecObj 2: Implementation of the Logic}

We have produced an implementation of {\churchqe} called
{\HLQE}~\cite{CaretteFarmerLaskowski18} by modifying
{\HL}~\cite{Harrison09}, a simple implementation of the {\HOL} proof
assistant~\cite{GordonMelham93}.  {\HLQE} provides a built-in global
infrastructure for metareasoning with reflection.  Over the next
couple years we plan to test this infrastructure by formalizing a
variety of SBMAs in {\HLQE}.

\subsection*{SpecObj 3: Biform Theories}

No work on this objective has been done, but we expect it will be a
straightforward task to implement biform theories and the application
of external transformer in {\HLQE}.

\subsection*{SpecObj 4: Biform Theory Graphs}

We proposed in~\cite{CaretteFarmer17} a biform theory graph test case
consisting of eight biform theories encoding natural number
arithmetic.  We produced partial formalizations of this test
case~\cite{CaretteFarmer17} in {\churchuqe}~\cite{Farmer17} using the
global approach for metareasoning with reflection and in
Agda~\cite{Norell07,Norell09} using the local approach.  After we have
finished with SpecObj 2 and SpecObj 3, we intend to formalize this
test case in {\HLQE}.

\subsection*{SpecObj 5: Specializable Transformers}

\todo{Jacques should complete this subsection.  Please reference
  Pouya's thesis~\cite{Larjani13}.}



\section{Related Work}

\todo{Jacques should complete this section, referring as necessary to
  the related work section in~\cite{Farmer18}.}

\section{Conclusion}

\bibliography{imps}
\bibliographystyle{plain}

\setcounter{tocdepth}{1}
\listoftodos
\setcounter{tocdepth}{0}

\end{document}
